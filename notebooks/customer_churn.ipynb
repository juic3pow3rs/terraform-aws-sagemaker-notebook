{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting whether to contact a customer because they are at risk of churning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For updates on the way Sagemaker or AWS behave compared to the notebook code, please refer to https://livebook.manning.com/#!/book/machine-learning-for-business/chapter-3/v-5/119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load and examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Zelle bitte den eigenen Ablageort übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = 'martin-mlforbusiness'\n",
    "subfolder = 'ch03'\n",
    "dataset = 'churn_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import s3fs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "s3 = s3fs.S3FileSystem(anon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churned</th>\n",
       "      <th>id</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>co_name</th>\n",
       "      <th>total_spend</th>\n",
       "      <th>week_minus_4</th>\n",
       "      <th>week_minus_3</th>\n",
       "      <th>week_minus_2</th>\n",
       "      <th>last_week</th>\n",
       "      <th>4-3_delta</th>\n",
       "      <th>3-2_delta</th>\n",
       "      <th>2-1_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1826</td>\n",
       "      <td>Hoffman Martinez and Chandler</td>\n",
       "      <td>68567.34</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>772</td>\n",
       "      <td>Lee Martin and Escobar</td>\n",
       "      <td>74335.27</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>479</td>\n",
       "      <td>Hobbs Mcdaniel and Baker</td>\n",
       "      <td>48746.22</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.12</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1692</td>\n",
       "      <td>Williams-Harris</td>\n",
       "      <td>64416.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2578</td>\n",
       "      <td>Beck-Snyder</td>\n",
       "      <td>71623.20</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churned  id  customer_code                        co_name  total_spend  \\\n",
       "0        0   1           1826  Hoffman Martinez and Chandler     68567.34   \n",
       "1        0   2            772         Lee Martin and Escobar     74335.27   \n",
       "2        0   3            479       Hobbs Mcdaniel and Baker     48746.22   \n",
       "3        0   4           1692                Williams-Harris     64416.70   \n",
       "4        0   5           2578                    Beck-Snyder     71623.20   \n",
       "\n",
       "   week_minus_4  week_minus_3  week_minus_2  last_week  4-3_delta  3-2_delta  \\\n",
       "0          0.81          0.02          0.74       1.45      -0.79       0.72   \n",
       "1          1.87          1.02          1.29       1.19      -0.85       0.27   \n",
       "2          1.21          0.70          1.04       2.12      -0.51       0.34   \n",
       "3          0.75          2.08          2.40       2.02       1.33       0.32   \n",
       "4          2.33          0.66          1.97       1.60      -1.67       1.31   \n",
       "\n",
       "   2-1_delta  \n",
       "0       0.71  \n",
       "1      -0.10  \n",
       "2       1.08  \n",
       "3      -0.38  \n",
       "4      -0.37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f's3://{data_bucket}/{subfolder}/{dataset}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frage 1\n",
    "\n",
    "**Welche Reihen sind Categorical Features?**\n",
    "\n",
    ">1. churned, last_week, co_name\n",
    ">2. id, customer_code, co_name\n",
    ">3. 4-3_delta, 3-2_delta, 2-1_delta\n",
    ">4. id, total_spend, last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 2999\n",
      "0    2833\n",
      "1     166\n",
      "Name: churned, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in dataset: {df.shape[0]}')\n",
    "print(df['churned'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Get the data into the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churned</th>\n",
       "      <th>total_spend</th>\n",
       "      <th>week_minus_4</th>\n",
       "      <th>week_minus_3</th>\n",
       "      <th>week_minus_2</th>\n",
       "      <th>last_week</th>\n",
       "      <th>4-3_delta</th>\n",
       "      <th>3-2_delta</th>\n",
       "      <th>2-1_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68567.34</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>74335.27</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>48746.22</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.12</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>64416.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>71623.20</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churned  total_spend  week_minus_4  week_minus_3  week_minus_2  last_week  \\\n",
       "0        0     68567.34          0.81          0.02          0.74       1.45   \n",
       "1        0     74335.27          1.87          1.02          1.29       1.19   \n",
       "2        0     48746.22          1.21          0.70          1.04       2.12   \n",
       "3        0     64416.70          0.75          2.08          2.40       2.02   \n",
       "4        0     71623.20          2.33          0.66          1.97       1.60   \n",
       "\n",
       "   4-3_delta  3-2_delta  2-1_delta  \n",
       "0      -0.79       0.72       0.71  \n",
       "1      -0.85       0.27      -0.10  \n",
       "2      -0.51       0.34       1.08  \n",
       "3       1.33       0.32      -0.38  \n",
       "4      -1.67       1.31      -0.37  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = df.drop(['id', 'customer_code', 'co_name'], axis=1)\n",
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frage 2\n",
    "\n",
    "**Warum werden diese Feature-Columns entfernt?**\n",
    "\n",
    ">1. Categorical Daten müssen später separat trainiert werden.\n",
    ">2. String-Values (Zeichenketten) können nur in Modellen für Natural-Language-Processing verarbeitet werden.\n",
    ">3. Diese drei Features bringen für das Training in diesem Business-Case keinen Mehrwert.\n",
    ">4. Categorical Daten können generell nicht für ein Modelltraining genutzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Create training, validation and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offene Frage\n",
    "**Welche Funktion haben die jeweiligen Sets?**\n",
    "\n",
    "**Welche Größe haben die Sets \"test\", \"val\", \"train\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099, 9) (600, 9) (300, 9)\n",
      "\n",
      "Number of rows in Train dataset: {train_df.shape[0]}\n",
      "0    1983\n",
      "1     116\n",
      "Name: churned, dtype: int64\n",
      "\n",
      "Number of rows in Validate dataset: {val_df.shape[0]}\n",
      "0    567\n",
      "1     33\n",
      "Name: churned, dtype: int64\n",
      "\n",
      "Number of rows in Test dataset: {test_df.shape[0]}\n",
      "0    283\n",
      "1     17\n",
      "Name: churned, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = encoded_data['churned']\n",
    "train_df, test_and_val_data, _, _ = train_test_split(encoded_data, y, test_size=0.3, stratify=y, random_state=0)\n",
    "\n",
    "y = test_and_val_data['churned']\n",
    "val_df, test_df, _, _ = train_test_split(test_and_val_data, y, test_size=0.333, stratify=y, random_state=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "print()\n",
    "print('Number of rows in Train dataset: {train_df.shape[0]}')\n",
    "print(train_df['churned'].value_counts())\n",
    "print()\n",
    "print('Number of rows in Validate dataset: {val_df.shape[0]}')\n",
    "print(val_df['churned'].value_counts())\n",
    "print()\n",
    "print('Number of rows in Test dataset: {test_df.shape[0]}')\n",
    "print(test_df['churned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.to_csv(None, header=False, index=False).encode()\n",
    "val_data = val_df.to_csv(None, header=False, index=False).encode()\n",
    "test_data = test_df.to_csv(None, header=True, index=False).encode()\n",
    "\n",
    "with s3.open(f'{data_bucket}/{subfolder}/processed/train.csv', 'wb') as f:\n",
    "    f.write(train_data)\n",
    "\n",
    "with s3.open(f'{data_bucket}/{subfolder}/processed/val.csv', 'wb') as f:\n",
    "    f.write(val_data) \n",
    "    \n",
    "with s3.open(f'{data_bucket}/{subfolder}/processed/test.csv', 'wb') as f:\n",
    "    f.write(test_data) \n",
    "    \n",
    "train_input = sagemaker.inputs.TrainingInput(s3_data=f's3://{data_bucket}/{subfolder}/processed/train.csv', content_type='csv')\n",
    "val_input = sagemaker.inputs.TrainingInput(s3_data=f's3://{data_bucket}/{subfolder}/processed/val.csv', content_type='csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frage 3\n",
    "\n",
    "**Was bedeutet Overfitting?**\n",
    "\n",
    ">1. Das trainierte Modell wird immer besser.\n",
    ">2. Für das Training des Modells steht zu wenig Rechenleistung zur Verfügung. \n",
    ">3. Das Trainingsset für das Modell hat zu viele Features.\n",
    ">4. Das trainierte Modell lernt zu stark von den Trainingsdaten. In der Folge wird die Vorhersage schwächer für reale Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter\n",
    "**Mit welchen Werten arbeiten wir während des Trainings?**\n",
    "\n",
    "**max_depth**\n",
    "Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "\n",
    "**subsample**\n",
    "Subsample ratio of the training instances. \n",
    "Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. \n",
    "This will prevent overfitting.\n",
    "\n",
    "**objective**\n",
    "You set this hyperparameter to binary:logistic. You use this setting when your target variable is 1 or 0. \n",
    "If your target variable is a multiclass variable or a continuous variable, then you use other settings.\n",
    "\n",
    "**eval_metric**\n",
    "The evaluation metric you are optimizing for. The metric argument auc stands for area under the curve.\n",
    "\n",
    "**num_round**\n",
    "How many times you want to let the machine learning model run through the training data (the number of rounds). \n",
    "With each loop through the data, the function gets better at separating the dark circles from the light circles. \n",
    "After a while though, the model gets too good; \n",
    "It begins to find patterns in the test data that are not reflected in the real world. This is called overfitting.\n",
    "To avoid this, you set early stopping rounds.\n",
    "\n",
    "> Mehr Runden sind also immer besser, stimmt's?\n",
    "\n",
    "**early_stopping_rounds**\n",
    "The number of rounds where the algorithm fails to improve.\n",
    "\n",
    "**scale_pos_weight**\n",
    "The scale positive weight is used with imbalanced datasets to make sure \n",
    "the model puts enough emphasis on correctly predicting rare classes during training. \n",
    "In the current dataset, about 1 in 17 customers will churn.\n",
    "So we set scale_pos_weight to 17 to accommodate for this imbalance. \n",
    "This tells XGBoost to focus more on customers who actually churn \n",
    "rather than on happy customers who are still happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning in Action\n",
    "\n",
    "**Im ersten Durchgang mit folgenden Hyperparamtern bis Deploy und Prediction**\n",
    "* max_depth=1\n",
    "* subsample=0.1\n",
    "\n",
    "**Ergebnisse Durchlauf 1**\n",
    "* train-auc:\n",
    "* validation-auc:\n",
    "* anzahl rounds:\n",
    "* accuracy_score:\n",
    "\n",
    "**Im zweiten Durchgang mit folgenden Hyperparamtern bis Deploy und Prediction**\n",
    "* max_depth=3\n",
    "* subsample=0.7\n",
    "\n",
    "**Ergebnisse Durchlauf 2**\n",
    "* train-auc:\n",
    "* validation-auc:\n",
    "* anzahl rounds:\n",
    "* accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-07 07:49:11 Starting - Starting the training job...ProfilerReport-1670399351: InProgress\n",
      "...\n",
      "2022-12-07 07:49:48 Starting - Preparing the instances for training.........\n",
      "2022-12-07 07:51:27 Downloading - Downloading input data.........\n",
      "2022-12-07 07:53:08 Training - Downloading the training image.........\n",
      "2022-12-07 07:54:36 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-12-07:07:54:40:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-12-07:07:54:40:INFO] File size need to be processed in the node: 0.12mb. Available memory size in the node: 8834.91mb\u001b[0m\n",
      "\u001b[34m[2022-12-07:07:54:40:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:54:40] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:54:40] 2099x8 matrix with 16792 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-12-07:07:54:40:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:54:40] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[07:54:40] 600x8 matrix with 4800 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.723549#011validation-auc:0.777457\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-auc' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-auc hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.934545#011validation-auc:0.940383\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.938342#011validation-auc:0.924483\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.938029#011validation-auc:0.924029\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.945589#011validation-auc:0.934718\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.948156#011validation-auc:0.935706\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.946#011validation-auc:0.934798\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.948156#011validation-auc:0.93576\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.957516#011validation-auc:0.945861\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.956192#011validation-auc:0.944578\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.95566#011validation-auc:0.945781\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[11]#011train-auc:0.957918#011validation-auc:0.949174\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[12]#011train-auc:0.961942#011validation-auc:0.954572\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[13]#011train-auc:0.960655#011validation-auc:0.954064\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[14]#011train-auc:0.962696#011validation-auc:0.956737\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[15]#011train-auc:0.967643#011validation-auc:0.964646\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[16]#011train-auc:0.967506#011validation-auc:0.96315\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[17]#011train-auc:0.966528#011validation-auc:0.965234\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[18]#011train-auc:0.965726#011validation-auc:0.964005\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-auc:0.968726#011validation-auc:0.965395\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[20]#011train-auc:0.968676#011validation-auc:0.964673\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[21]#011train-auc:0.968328#011validation-auc:0.965208\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[22]#011train-auc:0.970473#011validation-auc:0.964165\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[23]#011train-auc:0.969449#011validation-auc:0.965662\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[24]#011train-auc:0.969591#011validation-auc:0.964379\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[25]#011train-auc:0.969615#011validation-auc:0.963203\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[26]#011train-auc:0.970251#011validation-auc:0.96315\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[27]#011train-auc:0.96923#011validation-auc:0.964112\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[28]#011train-auc:0.969632#011validation-auc:0.964272\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[29]#011train-auc:0.970369#011validation-auc:0.963738\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[30]#011train-auc:0.969797#011validation-auc:0.963016\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[31]#011train-auc:0.970182#011validation-auc:0.964353\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[32]#011train-auc:0.970186#011validation-auc:0.966063\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[33]#011train-auc:0.970182#011validation-auc:0.964887\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.968743#011validation-auc:0.966651\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[35]#011train-auc:0.966163#011validation-auc:0.958474\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[36]#011train-auc:0.965324#011validation-auc:0.957939\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[37]#011train-auc:0.963802#011validation-auc:0.95818\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[38]#011train-auc:0.962509#011validation-auc:0.960665\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[39]#011train-auc:0.9651#011validation-auc:0.959382\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[40]#011train-auc:0.965909#011validation-auc:0.95858\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[41]#011train-auc:0.9665#011validation-auc:0.957031\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[42]#011train-auc:0.966008#011validation-auc:0.957779\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[43]#011train-auc:0.966371#011validation-auc:0.958099\u001b[0m\n",
      "\u001b[34m[07:54:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[44]#011train-auc:0.965172#011validation-auc:0.954893\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[34]#011train-auc:0.968743#011validation-auc:0.966651\u001b[0m\n",
      "\n",
      "2022-12-07 07:55:09 Uploading - Uploading generated training model\n",
      "2022-12-07 07:55:09 Completed - Training job completed\n",
      "Training seconds: 218\n",
      "Billable seconds: 218\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "from sagemaker import image_uris \n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "                        container, \n",
    "                        role,\n",
    "                        instance_count=1, \n",
    "                        instance_type='ml.m4.xlarge',\n",
    "                        output_path=f's3://{data_bucket}/{subfolder}/output',\n",
    "                        sagemaker_session=sess)\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "                        max_depth=1,\n",
    "                        subsample=0.1,\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        num_round=100,\n",
    "                        early_stopping_rounds=10,\n",
    "                        scale_pos_weight=17)\n",
    "\n",
    "estimator.fit({'train': train_input, 'validation': val_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Host the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'customer-churn'\n",
    "\n",
    "try:\n",
    "    sess.delete_endpoint(endpoint_name)\n",
    "    sess.delete_endpoint_config(endpoint_name)\n",
    "    print('Warning: Existing endpoint deleted to make way for your new endpoint.')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.m4.xlarge',\n",
    "            endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churned</th>\n",
       "      <th>total_spend</th>\n",
       "      <th>week_minus_4</th>\n",
       "      <th>week_minus_3</th>\n",
       "      <th>week_minus_2</th>\n",
       "      <th>last_week</th>\n",
       "      <th>4-3_delta</th>\n",
       "      <th>3-2_delta</th>\n",
       "      <th>2-1_delta</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76897.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19604.63</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23369.60</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40709.47</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>69953.52</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>71939.07</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>45930.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>47080.25</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>35506.83</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>39188.12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churned  total_spend  week_minus_4  week_minus_3  week_minus_2  last_week  \\\n",
       "0        0     76897.46          0.56          2.29          1.14       2.23   \n",
       "1        0     19604.63          1.95          2.04          0.82       1.62   \n",
       "2        0     23369.60          1.11          1.54          1.55       1.14   \n",
       "3        1     40709.47          2.40          1.87          0.07       0.61   \n",
       "4        0     69953.52          2.01          1.20          1.05       1.41   \n",
       "5        0     71939.07          0.54          1.17          0.21       2.29   \n",
       "6        0     45930.53          0.08          1.43          0.41       1.34   \n",
       "7        0     47080.25          1.54          0.68          0.80       0.54   \n",
       "8        0     35506.83          1.37          0.93          1.70       0.67   \n",
       "9        0     39188.12          0.40          1.86          0.10       0.82   \n",
       "\n",
       "   4-3_delta  3-2_delta  2-1_delta  prediction  \n",
       "0       1.73      -1.15       1.09           0  \n",
       "1       0.09      -1.22       0.80           0  \n",
       "2       0.43       0.01      -0.41           0  \n",
       "3      -0.53      -1.80       0.54           0  \n",
       "4      -0.81      -0.15       0.36           0  \n",
       "5       0.63      -0.96       2.08           0  \n",
       "6       1.35      -1.02       0.93           0  \n",
       "7      -0.86       0.12      -0.26           0  \n",
       "8      -0.44       0.77      -1.03           0  \n",
       "9       1.46      -1.76       0.72           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prediction(row):\n",
    "    prob = float(predictor.predict(row[1:]))\n",
    "    return 1 if prob > 0.5 else 0\n",
    "\n",
    "with s3.open(f'{data_bucket}/{subfolder}/processed/test.csv') as f:\n",
    "    test_data = pd.read_csv(f)\n",
    "\n",
    "test_data['prediction'] = test_data.apply(get_prediction, axis=1)\n",
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    283\n",
      "1     17\n",
      "Name: churned, dtype: int64\n",
      "0    266\n",
      "1     34\n",
      "Name: prediction, dtype: int64\n",
      "0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "print(test_data['churned'].value_counts())\n",
    "print(test_data['prediction'].value_counts())\n",
    "print(metrics.accuracy_score(test_data['churned'],test_data['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260  23]\n",
      " [  6  11]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test_data['churned'],test_data['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frage 4\n",
    "\n",
    "**Offene Frage: Was bedeuten die Werte der Konfusion-Matrix und was sagt uns die Matrix über die Performance unseres Modells?**\n",
    "\n",
    "\n",
    "                        |         Predicted Values\n",
    "                        |    Positives    |   Negatives\n",
    "    - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "             Positives  | True Positives  | False Negatives\n",
    "     Actual - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "             Negatives  | False Positives | True Negatives\n",
    "\n",
    "\n",
    "**Carlos möchte jeden Kunden identifizieren, der Potential für einen Wechsel zur Konkurrenz zeigt. Welchem Feld sollte Carlos die größte Beachtung schenken, um die Modellqualität zu beurteilen?**\n",
    "\n",
    "                        |         Predicted Values\n",
    "                        |    Happy (0)    |    Unhappy (1)\n",
    "    - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "             Happy (0)  |      ( A )      |      ( B )      \n",
    "     Actual - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "           Unhappy (1)  |      ( C )      |      ( D )      \n",
    "\n",
    "\n",
    ">1. A\n",
    ">2. B\n",
    ">3. C\n",
    ">4. D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the Endpoint (optional)\n",
    "Comment out this cell to remove the endpoint if you want the endpoint to exist after \"run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
